http://conversations.e-flux.com/t/live-blog-the-new-centre-2016-nyc-summer-residency-july-18-22/4077/48

What does it mean to accelerate the general intellect in the age of artificial intelligence? #AGI begins from the investigation of distributed networks from which thought assembles and into which it disperses. Unlike in the past, general intelligence, algorithms, and networks are together becoming as irreducible to the efforts of “universal” intellectuals as cultural and political movements have become to “universal” leaders. Will the future enable a more radical, integrated, but also more complex mode of cultural and political engagement? One predicated upon what Marx describes as, “the conditions of the process of social life itself… under the control of the general intellect” (1).

AGI explores the new intensifying developments in the field of AI that are making possible subjectless modes of the general intellect, more collective and more general than any single individual or network.

Pete Wolfendale /// Towards Computational Kantianism
July 18 2016 @ 10:00 - 13:00 (Pratt Institute)
There are many ways to describe the purpose and significance of Immanuel Kant’s critical philosophy, but it is clear that the project of transcendental psychology, or the conditions of possibility of having a mind, or being capable of thought and action, is at the core of this philosophy. The premise of this seminar is that this project is essentially the same as the program of artificial general intelligence (AGI), and that by reading Kant’s work through contemporary developments in logic, mathematics, and computer science, that we can use this work to provide important methodological and technical insights for the AGI program. The seminar will begin by considering overall methodological issues, before describing the core ideas of Kant’s transcendental psychology, explaining the key ideas required to reconstruct it, and then proceeding to relate these to contemporary ideas, focusing on Robert Harper’s notion of computational trinitarianism, and the historical developments that lead up to it and the project of Homotopy Type Theory (HoTT) that inspired it. The seminar will close by considering some more general philosophical implications of the model provided.

.1.1.1 Pete Wolfendale: toward computational Kantianism

What is AGI?
AGI is both a subfield of AI and the 'subfield' from which AI research in general has sprung
What does the 'G' stand for/what does general(ized) mean in this context? This is a conceptual question which marks the extension of the AGI question beyond the parochial problem-solving questions instantiated by other subfields of AI. Taken seriously - i.e. as something other than an anthroponomic standard of human-levelness, -likeness, or -tractability - the generality pursued in AGI is absolute, qualitative, and abstract; or rather, as something systematically more than simply relative, quantitative, and/or concrete.

The Wozniak test: 'An AGI should be able to walk into an arbitrary house and make a cup of coffee'. As a rule of thumb, this is part of series of potential such rules of thumb that extends, for example, to 'an AGI should be able to terraform an arbitrary planet'. A generality that is common across these scales of Wozniak-satisfiability is what is posited and sought by AGI.

.1.1.2
We can map this to Kant's problematic from a variety of angles - putting AGIs alongside angels and aliens in Kant's thought-experimental references as 'abstraction(s) from below', understanding transcendental psychology as 'abstraction from above', object individuation in machine vision as engineering from within the Copernican turn, etc.

Beyond the frame problem
Isolating (from) certain parts of contexts - mice's flight across the floor from atmospheric dynamics or more appositely the nature of the lab as a general context - is both a positive computational achievement because it makes the problem of solving a maze or fleeing a predator tractable and well-refined, and at the same time the immediate or local limit to genuine learning which prevents mice from escaping the maze, killing the researchers and emancipating themselves. What we need is unframing and reframing as well as, or rather than, to provide access to the 'entire' frame.
Language is the killer app of human intelligence because it allows us to unframe and selectively reframe problems, constructively presupposing total logical plasticity, that anything can (theoretically) be symbolically represented in language, and the 'frame problem' is an effect of this.

Analogical bootstrapping: using (our) general intelligence to work on practical analogies to general intelligence like problem-solving in order to get back to general intelligence (again), closing - ideally - a construction loop.
Broadly, Kant gives us a variety of powerful ways to (generally) characterize the problem itself - and in its own terms?

Pete: real AGIs near-term are going to look more like children, probably specifically autistic children and savants, than suddenly-awoken Skynet, and our legal approach to them and their arising is probably going to have to look similar. He links this to the way that children and childraising are the 'loose thread' in liberal political philosophy inasmuch as they deal with the only universal, obligatory example of actually having to deal with developing-autonomy rather than formally positing it.

.1.1.3 Reconstructing Kant
For Kant, experience is judgment (we see what is as (what) it is). Understanding deals with concepts: general terms - which judgments connect (eg. Socrates and man, man and mortal) - in the unfolding of syllogism (in experience) which reason derives and retains new information from the consequent/ces of.
Sensibility deals with singular rather than general (conceptual, term-oriented) judgments - it is sensibility whereby the mind is given singularities that elementarily update the world and perturbate understanding (the space of the concept).

Kant's problematic is the structural interface in judgment between the singular and the general: the question of real experience, or objective validity: What is it to be responsible for an objective judgment, and to be capable of this responsibility?
How is it that we can say that gas over there is oxygen and that this means we know X and Y about it, its behavior, and its world, and have these (known to) be statements connected with the world and not merely manipulation of linguistic tokens in a closed/free-floating logical system?
How do objects and concepts constrain one another?

Kant: intuition of objects is synthetic and constructed. This is his radical departure from Aristotle and the essence of the Copernican turn, whereby we are not pre-related to objects which are elementarily given to us. You can't work on machine vision and not have this objectively demonstrated to you.
By constructing a singular instance with rules, the constructed instance becomes representative of the general or abstract case and not simply particular. This happens both in mathematical and experimental construction (Kant).

Out of Kant's transcendental method there are elements we should keep - transcendental psychology and deontology, which elaborate the synthetic a priori in the regimes of pure and practical reason respectively, and are useful 'abstractions from above' - and those we should not, like so-called transcendental reflection. Self-examination as a source of justification for statements about the transcendental constraints on mind leads us to phenomenological misuse - accidentally turning particular features of our sensorium into universalized features.

Similarly, aspects of computationalism which are principally useful include functionalism's abstraction/implementation loop; the formalism of information qua representation/synthesis loop that uses signal-extraction as a general characterization; and characteristic finitude, which we can gloss as 'ought implies can' and contrast with Kant's resort to infinite responsibilities in the second Critique. Pete also makes a distinction here between finite specification and finite execution, such that indefinite responsibilities (nonhalting execution) are OK if they can still be finitely specified - a deep computational principle.

.1.1.4 Transcendental Psychology = AGI
Kant's Principle of Consciousness: There is no consciousness without the possibility of self-consciousness.

Imagination understood (in part) as parochial processing includes: global integration of multi-modal sensory information, which we can relate to environmental simulation, global-workspace theories of consciousness, and the study of concurrency in computer science; extraction of local invariants such as object individuation; and
anticipation of local variations such as object simulation. Understanding, then, is general framing, and comprises classification of local invariants (generic judgment), re-identification of local invariants across contexts (recognitive judgment), and identification and classification of local variations (predicative judgment).

Reason, finally, describes general re-framing: extraction of judgment consequences through ampliative inference (abduction); identification of judgment conflicts or critical inference; and global integration of conceptually formatted information (world representation).

The full process moves through all three of these, including in loops where revision of conceptual structure requires reimagining - physically instantiated perhaps as reforming neural networks, or learning a new artistic or technical interface for interacting with or modeling the world - and vice-versa (re)integrating some experiences effectively in and through the imagination requires resort to or revision of extant conceptual apparatus.

.1.1.4 Key Questions/Provisional Answers
1. Why privilege judgment?

Computational Trinitarianism ramifies the operational structure of judgment into a triangular relationship between mathematics, logic, and computation. The Curry-Howard correspondence between functions and sets in type theory forms the logical-computational side of the triangle, syntactic categories in model-theory link logic and mathematics, and homotopy type theory links computation and mathematics by rendering all proofs computable, or equivalently any proof specified using it computer-checkable.

Why distinguish between sensibility and understanding?
Pete maps this distinction to mathematical-empirical 'duality' in the mathematical sense of stable operational inversions. Building on the trinitarian structure of judgment in the computational universe, there is a triad of relevant duals. In the logical domain, intuitionistic and co-intuitionistic logic are dual in a way we could roughly characterize as that of proof and exception. In the domain of formal (computational/programming) languages, recursive functions [λ] and co-recursive functions [ω] respectively generate halting and nonhalting recursive series', eg. enumeration vs indefinite loops. And in mathematics, we have inductive types from homotopy type theory and the open question of co-inductive types (dual HoTT(?)) - which might correspond to the duality of observation and manipulation.

What exactly is an imagination?
Kant's constructivism resurfaces in topos theory (generalization of topology via category theory) and dependent type theory (which reconnect in homotopy type theory), but without Kant's inhibiting focus on 'our' ('the') imagination rather than imaginations plural, as varying (un- or preconscious?) technical media with varying capabilities that take place, operate, and correspond or negotiate within the universal trinity of computational judgment.

The current status quo is groups working on a range of very specific implementation schemes for neural networks, worrying about the specific structure of the networks and thinking that one or some of these will be 'the (better) way' of deploying generalizable intelligent behavior. Instead, Pete suggests that we can use the natural types made available by homotopy type theory to develop new programming languages which would compile directly into recurrent neural networks or similar implementation structures. This seems to be where the rubber hits the road and the gears of 'abstraction from above' and 'abstraction from below' or parochial and universalist A(G)I work engage and become co-productive: a modality of abstraction-from-above that can break out of the inhibitive tendency to (become) 'self-implementation' via a descriptive regime that commensurates to the potential-autonomy or plasticity of the state-of-the-art (least-)parochial medium of implementation (learning networks) - the technological constitution of imaginations.

Practically posed, what you want is a regime of natural data structures with which to extract hidden-layer/evolved solutions from active neural networks, consistently abstract and reuse/-implement them. The theoretical means available for this appears when it turns out geometric logic is the internal logic of Grothendieck topoi, and so this natural/governing logic turns out to already be present in the structure of the simulation space in which experience takes place

.0.3 Abstract: New Centre #AGI panel at the Future of Mind conference

Panelists: Reza Negarestani, Patricia Reed, Pete Wolfendale
What does it mean to accelerate the general intellect in the age of artificial intelligence? #AGI begins from the investigation of distributed networks from which thought assembles and into which it disperses. Unlike in the past, general intelligence, algorithms, and networks are together becoming as irreducible to the efforts of “universal” intellectuals as cultural and political movements have become to “universal” leaders. Will the future enable a more radical, integrated, but also more complex mode of cultural and political engagement? One predicated upon what Marx describes as, “the conditions of the process of social life itself… under the control of the general intellect." #AGI explores the new intensifying developments in the field of AI that are making possible subjectless modes of the general intellect, more collective and more general than any single individual or network.

.3.0.1 Reza Negarestani: Language of General Intelligence (Future of Mind panel)

Abstract: Can general artificial intelligence be adequately defined or built without language? What is exactly in language that makes it imperative for the realization of higher cognitive-practical abilities? Arguments from the centrality of language as a social edifice are by no means new. In defining what language is and why it is necessary for the realization of general intelligence, it is easy to go astray: to associate language with an ineffable essence, to find its significance in some mythical social homogeneity between members of a community, or espouse dogmatic theories of meaning. While addressing some of these pitfalls, I would like to highlight the central role of language in the realization of higher cognitive abilities. To do so, I will provide a picture of language as a sui generis and multi-level computational system in which the indissociable syntactic, semantic and pragmatic aspects of language can be seen as a scaffolding for the generation of increasingly more complex cognitive and practical abilities.

.3.2 Reza Negarestani: Language of General Intelligence

Reza poses language as a fundamental computational interaction matrix - a matrix of interaction-as-computation - that facilitates qualitative compression and the modulation of behavior and internality among agents, rather than simply a symbolic regime. These agents are described in terms of computational dualities between role-switching systems or processes that reciprocally and dynamically constrain one another in being forced to correct each other's action series and augment their own interactive modes, driving the production of novel complexity. He goes on to discuss how the insights of this computational and ludic description of human/natural language apply and have failed to be applied in the deployment of artificial and formal languages. A language, or linguistic interaction-environment, that displays the full dynamicity and computational power he describes is a syntactic/semantic interface that has to be endowed with a pragmatics. The key to pursuing human-level artificial intelligences is to design multiagent environments in which interaction is a central motif and guiding matrix, at different and mutually reinforcing and regulating scales.

.4.3.1 Reza Negarestani: An Outside View of Ourselves as a Toy Model (of) AGI

Reza Negarestani's lecture can be roughly divided into three parts: a groundwork phase framing the transcendental ramifications of the question of the human for the project of AGI and vice-versa; the deployment of a toy model approach to investigating these relationships and their limits; and a demonstrative excursion into the problem of entropy and arrows of time in the context of Boltzmann's work in statistical thermodynamics.

Part 1 - Groundwork: problems of subjectivity for orienting the AGI project

Subjectivity, "discursive apperceptive intelligence", and the constraints it places on theorizing AGI are the central theme of this opening section. If we ask 'will AGI converge or diverge with humans?' it only makes sense to claim divergence if we are parochially limiting the (reference of the) human to its local particularity, whilst reducing convergence qua mirroring from a functional capacity to structural constitution or even a conflation of these two. The "inflationary" position with respect to the singularity of human intelligence, which believes artificial human-level intelligence (AHLI) to be impossible, and the 'deflationary' position which believes parochial and inductive methods to be sufficient for realizing AHLI, are in truth two sides of the "same provincial coin". The extreme subset of the latter group are 'hard parochialists' whose methodology is purely to abstract parochial modular functions from below and integrate them. In contrast, 'soft parochialism' (SP) poses 'human' as a set of cognitive practical abilities that are minimal but necessary for self-improvement, centrally the capacity for deliberate interaction founded on functional mirroring. It does not seek to limit the model of mirroring to human intelligence, but thinks that it is a necessary-but-insufficient component of such modeling.

Reza argues that this is simply a "more insidious form of anthropocentrism" and auto-occultation, and argues that SP's approach must be coupled with a critique that separates from particular, contingent transcendental structures of subjectivity - biological, cultural, historical, paradigmatic - because the limits of objective description of the human are set by the limits imposed in our own transcendental structures of self-regard which must therefore be systematically challenged. Taking the structures of our view of the structure of ourselves for granted inevitably constrains apprehension of AGI to essentialism about the human and renders us oblivious: a "transcendental blindspot". Thus the critique of transcendental structures and hard AGI research are parallel projects whose joint end is the fundamental alienation of the human from within, through rationally challenging the given facts of experience and reinventing its model outside of local transcendental constraints.

.4.3.1 Part 2 - the Outside view of ourselves as a toy model of AGI

The object of this phase of Reza's construction is a "global point of view that can make explicit implicit metatheoretical assumptions" in the thinking of human and artificial general intelligence, a sufficient but alterable metatheoretical model that can expose and reconfigure problems with the metatheoretical model it operates on, that is not just 'simple enough' but makes explicit or explicitly-different metatheoretical assumptions. This is where Reza deploys the toy model approach, taken from mathematical logic. A 'big' toy model, the kind that is useful for this project, supports model pluralism that can represent fissures between models but maintain invariant features. In contrast, the "AI winter" of the late 20th century that followed the syntactic mind project occurred because of a "unique and inflationary model of mind". Theoretical bottlenecks form a loop with practical setbacks when assumptions go unchallenged due to local successes, becoming globalized into observational general features, and it is this loop that the toy model approach is a weapon for breaking. By making the MTAs of their components explicit, toy models are able to engage in "theoretical arbitrage" that we learn from through systematically playing with the TM's capabilities and breaking it 'in real life' in the practical dialectic of metatheoretical conditions of observation and functional conditions of operation.

At this point the lecture becomes irreducibly dependent on a pair of extraordinary diagrams created by Reza that I hope to be able to post or link to here at a later date. For now, a few contextualizing points and a quotable moment:
- Fundamental axes: 1) what arises from the exercise of mind, and 2) what is required for the realization of (1) - or, "realizabilities and realizers".
- It is a methodological necessity to describe the toy-modeled intelligence as if an automaton, without internalities - see the framing arguments described above.
- Concepts are operations of qualitatively shifting compression that language qua sui generis computation facilitates to allow a growing internal model without exponentiating metabolic requirements.
- "Good predators are those whose invariances are extremely compressed."

The question of time transcendentally recurs at different levels of functioning through Reza's diagrams of small and big (Kantian and ramified) toy models of general intelligence, indicating a still-obscured way in which much of the contingent limits on transcendental characteristics of experience depend on the structure of subjective time (itself), or the "transcendental ideality of experience" (Kant). The provenance of 'nonagentic AGI' as a fundamental notion of the hard parochialists, among others, lies in giving probabilistic or inductive in(ter)ference strong causal powers. This move is also central to contemporary evolutionary biology and cognitive science, and is ultimately sourced from statistical thermodynamics - which leads Reza to the seminal work of Ludwig Boltzmann in that field.

.4.3.3 Part 3 - beyond (asymmetric) time

[This was a complex and involved discussion that I will treat fairly quickly here, pending more personal research into some of the underlying concepts.]

The takeaway from reading Boltzmann's The Unreality of Time can be extracted in modest and sinister versions.
Modest: We can neither draw conclusions about time nor about the existence of such conclusions to be drawn from the conditions of experience. Temporal dynamics do not reflect or entail observational time, and thus predicative judgments via language can be treated neither as pieces of evidence nor metafactual components.
Sinister: All punctual and durational assignments, the identity of the present, and any determination based on time-asymmetry is riddled with fundamental mistakes, impossibilities, and biases. This includes the idea of the 'observer' in physics as well as basic theoretical elements like causality, antecedent, state, and boundary conditions - inasmuch as these remain dependent on asymmetry. Any revision of the canonical time-model carries devastating consequences for complexity science.

Rather than 'why does entropy increase toward the future?' the real conundrum is 'why does entropy decrease toward the past?' Entropy just is the overwhelming likelihood that any physical microstate is part of an arbitrarily large coarse-graining region of macroscopically indistinguishable microstates, such that any vector in phase space transitioning between these regions almost certainly moves from a smaller to a larger one. The question is why there should be a steep local gradient in the size of these regions and consequently [... see how hard it is?] the intense continuous stream of transitions between them (dissipative activity of a low-entropy past) that we find occurring - rather than a low-transition relative uniformity 'in both directions'. (Thus, pace ontology, it's less an issue of why than where there should be something rather than nothing.)

Boltzmann reframes this as a problem of moving between micro- and macrostates in the process of making entropy assignments, identifying three descriptive levels (intermediated by renormalization spaces):
1. Pure, based on abstract generality of differential equations
2. Indirect, based on probabilistic interpretations
3. Direct, based on physical observables
The tendency toward more probable macrostates (over)determines the extraction of entropy assignments from microstates governed by time-symmetric physics.

'The whole idea that two particles that have not collided yet are not correlated is based on time-asymmetric causal assumption, unjustly inconsistent with the assumption that particles will be correlated after colliding even if they never encounter each other again in the future - and this is the parochial transcendental structure of [(the)] observation.'

How can we suggest that an initial microstate explains a final macrostate? The human is the possibility of this that requires an explanation - which cannot be already within its own terms.

"Time accommodates no one.
Why worry about being lost in it?"

//

The big takeaways for AGI:

A challenge: to think the agency beyond any locally posited transcendental conditions
A question: what are the implications of nondirectional time and of the atemporal model?
"Genuine self-consciousness," Reza concludes, "is an outside view of itself."

"A view from nowhen."
